"""
MP3 to Text Converter - Core Module
===================================
Converts MP3/WAV audio files to text using faster-whisper.
Completely free and runs locally (offline).

Usage:
    python mp3_to_text.py                    # Interactive mode
    python mp3_to_text.py audio.mp3          # CLI mode
    python mp3_to_text.py audio.mp3 -o out.txt  # Save to file
"""

import os
import sys
import argparse
import warnings
from pathlib import Path

# Windows UTF-8 ì¶œë ¥ ì„¤ì • (cp949 ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

# Optional: Progress bar
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False

# Check if faster-whisper is installed
try:
    from faster_whisper import WhisperModel
except ImportError:
    print("âŒ 'faster-whisper' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install faster-whisper")
    print("   ë˜í•œ ffmpegê°€ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    print("   ë˜í•œ ffmpegê°€ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    sys.exit(1)

# Audio preprocessing
try:
    from pydub import AudioSegment
    import tempfile
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False


def preprocess_audio(audio_path: str, target_sample_rate: int = 16000) -> str:
    """
    ì˜¤ë””ì˜¤ë¥¼ Whisper ìµœì  í¬ë§·ìœ¼ë¡œ ì „ì²˜ë¦¬.
    - 16kHz ìƒ˜í”Œë ˆì´íŠ¸
    - ëª¨ë…¸ ì±„ë„
    - WAV í¬ë§·
    """
    if not PYDUB_AVAILABLE:
        return audio_path
    
    try:
        # ì˜¤ë””ì˜¤ ë¡œë“œ (í•œê¸€ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬)
        audio_path_resolved = str(Path(audio_path).resolve())
        print(f"ğŸ”„ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì¤‘... (16kHz ëª¨ë…¸ ë³€í™˜)")
        audio = AudioSegment.from_file(audio_path_resolved)
        
        # ëª¨ë…¸ ë³€í™˜
        if audio.channels > 1:
            audio = audio.set_channels(1)
        
        # 16kHz ë¦¬ìƒ˜í”Œë§
        if audio.frame_rate != target_sample_rate:
            audio = audio.set_frame_rate(target_sample_rate)
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        audio.export(temp_file.name, format="wav")
        temp_file.close()
        
        return temp_file.name
        
    except Exception as e:
        print(f"âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
        return audio_path


def get_audio_duration(audio_path: str) -> float:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì´ ê¸¸ì´(ì´ˆ)ë¥¼ ë°˜í™˜.
    """
    if not PYDUB_AVAILABLE:
        return 0.0
    
    try:
        # í•œê¸€ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬
        audio_path_resolved = str(Path(audio_path).resolve())
        audio = AudioSegment.from_file(audio_path_resolved)
        return len(audio) / 1000.0  # ë°€ë¦¬ì´ˆ â†’ ì´ˆ
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
        return 0.0


def format_time(seconds: float) -> str:
    """ì´ˆë¥¼ MM:SS ë˜ëŠ” HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
    if seconds < 0:
        return "--:--"
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    return f"{minutes:02d}:{secs:02d}"


class MP3ToTextConverter:
    """
    MP3/WAV íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤.
    
    Attributes:
        model_size: ëª¨ë¸ í¬ê¸° ('small', 'medium', 'large', 'large-v3')
        device: ì‹¤í–‰ ì¥ì¹˜ ('cuda' or 'cpu')
        language: ë³€í™˜ ì–¸ì–´ (ê¸°ë³¸ê°’: 'ko' í•œêµ­ì–´)
    """
    
    # ëª¨ë¸ í¬ê¸°ë³„ íŠ¹ì„±
    MODEL_INFO = {
        "small": {"size": "~250MB", "speed": "ë¹ ë¦„", "accuracy": "ì–‘í˜¸"},
        "medium": {"size": "~750MB", "speed": "ë³´í†µ", "accuracy": "ì¢‹ìŒ"},
        "large": {"size": "~1.5GB", "speed": "ëŠë¦¼", "accuracy": "ë§¤ìš° ì¢‹ìŒ"},
        "large-v3": {"size": "~3GB", "speed": "ê°€ì¥ ëŠë¦¼", "accuracy": "ìµœê³  (í•œêµ­ì–´ ì¶”ì²œ)"},
    }
    
    def __init__(self, model_size: str = "large-v3", device: str = "auto", 
                 language: str = "ko", use_vad: bool = False, use_context: bool = False,
                 bgm_mode: bool = True, auto_clean_hallucination: bool = True):
        """
        ë³€í™˜ê¸° ì´ˆê¸°í™”.
        
        Args:
            model_size: ëª¨ë¸ í¬ê¸° (small, medium, large, large-v3)
            device: 'cuda', 'cpu', ë˜ëŠ” 'auto' (ìë™ ê°ì§€)
            language: ë³€í™˜ ì–¸ì–´ ì½”ë“œ (ko, en, ja ë“±)
            use_vad: VAD í•„í„° ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: False, ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬)
            use_context: ì´ì „ ë¬¸ë§¥ ê¸°ë°˜ ì¶”ë¡  ì—¬ë¶€ (ê¸°ë³¸: False, ì†ë„ ìš°ì„ )
            auto_clean_hallucination: ë³€í™˜ í›„ ìë™ìœ¼ë¡œ í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±° (ê¸°ë³¸: True)
            bgm_mode: ë°°ê²½ìŒì•… ëª¨ë“œ (ê¸°ë³¸: True, ë°°ê²½ìŒì•… ìœ„ ëª©ì†Œë¦¬ ì¶”ì¶œ ìµœì í™”)
        """
        self.model_size = model_size
        self.language = language
        self.use_vad = use_vad
        self.use_context = use_context
        self.bgm_mode = bgm_mode
        self.auto_clean_hallucination = auto_clean_hallucination
        
        # ìë™ ì¥ì¹˜ ê°ì§€ (ctranslate2 ê¸°ë°˜)
        if device == "auto":
            try:
                import ctranslate2
                # ctranslate2ë¡œ CUDA ì§€ì› ì—¬ë¶€ í™•ì¸
                cuda_types = ctranslate2.get_supported_compute_types("cuda")
                if cuda_types:
                    self.device = "cuda"
                else:
                    self.device = "cpu"
            except Exception:
                self.device = "cpu"
        else:
            self.device = device
        
        # ì¥ì¹˜ì— ë”°ë¥¸ ìµœì  ê³„ì‚° íƒ€ì…
        self.compute_type = "float16" if self.device == "cuda" else "float32"
        
        vad_status = "í™œì„±í™”" if use_vad else "ë¹„í™œì„±í™”"
        bgm_status = "í™œì„±í™”" if bgm_mode else "ë¹„í™œì„±í™”"
        print(f"ğŸ”§ ì„¤ì •: ëª¨ë¸={model_size}, ì¥ì¹˜={self.device}, ì–¸ì–´={language}, VAD={vad_status}, BGMëª¨ë“œ={bgm_status}")
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘... (ì²« ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤)")
        
        self.model = WhisperModel(
            model_size,
            device=self.device,
            compute_type=self.compute_type
        )
        
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    
    # í™˜ê°(Hallucination)ìœ¼ë¡œ ìì£¼ ë“±ì¥í•˜ëŠ” íŒ¨í„´ë“¤
    HALLUCINATION_PATTERNS = [
        "í•œê¸€ìë§‰", "ìë§‰ ì œì‘", "ìë§‰ by", "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤", 
        "ì‹œì²­í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤", "êµ¬ë…ê³¼ ì¢‹ì•„ìš”", 
        "ì˜ìƒ í¸ì§‘", "ì œì‘ ì§€ì›", "ë²ˆì—­ :", "ì‹±í¬ :", "ë°°ê¸‰ :",
        "í•œê¸€ ìë§‰", "by í•œíš¨ì •", "í•œê¸€ìë§‰ by í•œíš¨ì •", "ì•„ë©˜",
        "ì´ ì‹œê° ì„¸ê³„ì˜€ìŠµë‹ˆë‹¤", "ë ë", "ë‹¤ìŒ ì˜ìƒì—ì„œ ë§Œë‚˜ìš”",
        "ë‹¤ìŒ ì£¼ì— ë§Œë‚˜ìš”", "ë‹¤ìŒ ì‹œê°„ì— ëµ™ê² ìŠµë‹ˆë‹¤"
    ]

    def is_hallucination(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ í™˜ê°ì¸ì§€ íŒë³„"""
        if not text or len(text.strip()) == 0:
            return True
            
        # 1. ë°˜ë³µ íŒ¨í„´ ì²´í¬ (ì˜ˆ: "...." ë˜ëŠ” "??" ë°˜ë³µ)
        if len(text) > 10 and len(set(text)) < 5:
            return True
            
        # 2. ì•Œë ¤ì§„ í™˜ê° ë¬¸êµ¬ ì²´í¬
        for pattern in self.HALLUCINATION_PATTERNS:
            if pattern in text:
                return True
                
        return False

    def _transcribe_generator(self, audio_path: str, show_progress: bool = True):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë³€í™˜í•˜ëŠ” ì œë„ˆë ˆì´í„° (ìŠ¤íŠ¸ë¦¬ë°ìš©).
        Yields:
            (segment, info, total_duration, processed_path)
        """
        # í•œê¸€ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬: Path ê°ì²´ë¡œ ë³€í™˜
        audio_path_obj = Path(audio_path)
        if not audio_path_obj.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path_obj.name}")
        audio_path = str(audio_path_obj)  # ì •ê·œí™”ëœ ê²½ë¡œ ì‚¬ìš©
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
        total_duration = get_audio_duration(audio_path)
        if total_duration > 0:
            print(f"ğŸµ ë³€í™˜ ì¤‘: {audio_path} (ì´ {format_time(total_duration)})")
        else:
            print(f"ğŸµ ë³€í™˜ ì¤‘: {audio_path}")
        
        # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ìˆ˜í–‰
        processed_path = preprocess_audio(audio_path)
        process_audio_path = processed_path if processed_path != audio_path else audio_path
        
        # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        use_vad = getattr(self, 'use_vad', False)
        use_context = getattr(self, 'use_context', False)
        bgm_mode = getattr(self, 'bgm_mode', True)  # ê¸°ë³¸ê°’: True (ë°°ê²½ìŒì•… ëª¨ë“œ)
        
        # í•œêµ­ì–´ ì¸ì‹ ìœ ë„ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (í™˜ê° ë°©ì§€ìš©)
        initial_prompt = "[í•œê¸€ ìŒì„± ì¶”ì¶œ]" if self.language == 'ko' else None

        # ë°°ê²½ìŒì•… ëª¨ë“œ ì„¤ì •
        if bgm_mode:
            # ë°°ê²½ìŒì•… ìœ„ ëª©ì†Œë¦¬ ì¶”ì¶œ ìµœì í™” ì„¤ì •
            no_speech_threshold = 0.2  # ë‚®ì¶°ì„œ ë°°ê²½ìŒì•…ì´ ìˆì–´ë„ ìŒì„±ìœ¼ë¡œ ì¸ì‹
            log_prob_threshold = -1.5  # ë‚®ì¶°ì„œ ë¶ˆí™•ì‹¤í•œ ìŒì„±ë„ ìˆ˜ìš©
            compression_ratio_threshold = None  # ì••ì¶•ë¥  ì²´í¬ ë¹„í™œì„±í™”
            hallucination_silence_threshold = 0.3  # í™˜ê° ì–µì œ
            vad_threshold = 0.35  # VAD ì„ê³„ê°’ ë‚®ì¶¤ (ë” ë¯¼ê°í•˜ê²Œ)
            vad_min_speech_duration_ms = 200  # ì§§ì€ ìŒì„±ë„ ì¸ì‹
            vad_min_silence_duration_ms = 1000  # ì§§ì€ ì¹¨ë¬µ í—ˆìš©
        else:
            # ê¸°ë³¸ ì„¤ì •
            no_speech_threshold = 0.6
            log_prob_threshold = -1.0
            compression_ratio_threshold = 2.4
            hallucination_silence_threshold = None
            vad_threshold = 0.05
            vad_min_speech_duration_ms = 50
            vad_min_silence_duration_ms = 50

        if use_vad:
            segments, info = self.model.transcribe(
                process_audio_path,
                language=self.language,
                beam_size=5,
                condition_on_previous_text=use_context,
                temperature=0,  # ë°˜ë³µ íƒìƒ‰ ë°©ì§€
                initial_prompt=initial_prompt,
                vad_filter=True,
                vad_parameters=dict(
                    threshold=vad_threshold,
                    min_speech_duration_ms=vad_min_speech_duration_ms,
                    min_silence_duration_ms=vad_min_silence_duration_ms
                ),
                no_speech_threshold=no_speech_threshold,
                log_prob_threshold=log_prob_threshold,
                compression_ratio_threshold=compression_ratio_threshold,
                hallucination_silence_threshold=hallucination_silence_threshold,
            )
        else:
            if bgm_mode:
                print("âš ï¸ VAD ë¹„í™œì„±í™”: ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ë°°ê²½ìŒì•… ëª¨ë“œ í™œì„±í™”)")
            else:
                print("âš ï¸ VAD ë¹„í™œì„±í™”: ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬")
            segments, info = self.model.transcribe(
                process_audio_path,
                language=self.language,
                beam_size=5,
                condition_on_previous_text=use_context,
                temperature=0,
                initial_prompt=initial_prompt,
                vad_filter=False,
                no_speech_threshold=no_speech_threshold,
                log_prob_threshold=log_prob_threshold,
                compression_ratio_threshold=compression_ratio_threshold,
                hallucination_silence_threshold=hallucination_silence_threshold,
            )
        
        if show_progress:
            print("ğŸ“Š ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©:")
            print("   â³ ëª¨ë¸ ì²˜ë¦¬ ì¤‘... (ì²« ê²°ê³¼ê¹Œì§€ ì ì‹œ ëŒ€ê¸°)", end="", flush=True)
        
        first_segment = True
        for segment in segments:
            # í™˜ê° í•„í„°ë§
            if self.is_hallucination(segment.text):
                continue
            
            # ì²« ì„¸ê·¸ë¨¼íŠ¸ ì‹œ ëŒ€ê¸° ë©”ì‹œì§€ ì§€ìš°ê¸°
            if first_segment and show_progress:
                print("\r" + " " * 50 + "\r", end="", flush=True)
                first_segment = False
                
            yield segment, info, total_duration, processed_path

    def transcribe(self, audio_path: str, show_timestamps: bool = False, 
                   show_progress: bool = True) -> dict:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.
        
        Args:
            audio_path: MP3/WAV íŒŒì¼ ê²½ë¡œ
            show_timestamps: íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ ì—¬ë¶€
            show_progress: ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í‘œì‹œ ì—¬ë¶€
            
        Returns:
            dict: {
                'text': ì „ì²´ í…ìŠ¤íŠ¸,
                'language': ê°ì§€ëœ ì–¸ì–´,
                'language_probability': ì–¸ì–´ ê°ì§€ í™•ë¥ ,
                'segments': ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            }
        """
        segment_list = []
        full_text_parts = []
        info = None
        segment_count = 0
        processed_path = audio_path # Default, will be updated by generator
        
        import time as time_module
        start_time = time_module.time()
        
        for segment, info_obj, total_duration, gen_processed_path in self._transcribe_generator(audio_path, show_progress):
            if info is None: info = info_obj
            if processed_path == audio_path: processed_path = gen_processed_path # Capture processed_path once
            
            segment_count += 1
            segment_list.append({
                "start": segment.start,
                "end": segment.end,
                "text": segment.text
            })
            full_text_parts.append(segment.text)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            if show_progress:
                current_audio_time = segment.end
                elapsed_real_time = time_module.time() - start_time
                
                if total_duration > 0:
                    # ì§„í–‰ë¥  ê³„ì‚°
                    progress_pct = min(100, (current_audio_time / total_duration) * 100)
                    
                    # ETA ê³„ì‚° (í˜„ì¬ ì†ë„ ê¸°ì¤€)
                    if current_audio_time > 0:
                        speed_ratio = elapsed_real_time / current_audio_time
                        remaining_audio = total_duration - current_audio_time
                        eta_seconds = remaining_audio * speed_ratio
                    else:
                        eta_seconds = -1
                    
                    # ì§„í–‰ ë°” í‘œì‹œ
                    bar_width = 20
                    filled = int(bar_width * progress_pct / 100)
                    bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)
                    
                    # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (30ì ì œí•œ)
                    text_preview = segment.text[:25] + "..." if len(segment.text) > 25 else segment.text
                    
                    # ìƒíƒœ ë¼ì¸ ì¶œë ¥ (ê°™ì€ ì¤„ ë®ì–´ì“°ê¸°)
                    status = f"\r[{bar}] {progress_pct:5.1f}% | {format_time(current_audio_time)}/{format_time(total_duration)} | ETA: {format_time(eta_seconds)} | {text_preview}"
                    print(status.ljust(120), end="", flush=True)
                else:
                    # ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ëª¨ë¥¼ ë•ŒëŠ” ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ì™€ ì²˜ë¦¬ ì‹œê°„ë§Œ í‘œì‹œ
                    text_preview = segment.text[:30] + "..." if len(segment.text) > 30 else segment.text
                    print(f"\rì„¸ê·¸ë¨¼íŠ¸ {segment_count} | {format_time(current_audio_time)} | {text_preview}".ljust(100), end="", flush=True)
            
            if show_timestamps:
                print(f"\n  [{segment.start:.2f}s â†’ {segment.end:.2f}s] {segment.text}")
        
        # ì§„í–‰ í‘œì‹œ ì¢…ë£Œ (ì¤„ë°”ê¿ˆ)
        if show_progress:
            print()  # ìƒˆ ì¤„ë¡œ ì´ë™
            
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if processed_path != audio_path and os.path.exists(processed_path):
            try:
                os.unlink(processed_path)
            except:
                pass
        
        full_text = " ".join(full_text_parts).strip()
        
        result = {
            "text": full_text,
            "language": info.language,
            "language_probability": info.language_probability,
            "segments": segment_list
        }
        
        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! (ì´ {segment_count}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ê°ì§€ ì–¸ì–´: {info.language}, í™•ë¥ : {info.language_probability:.2%})")
        
        return result
    
    def _remove_hallucination(self, time_file: str) -> int:
        """
        time.md íŒŒì¼ì—ì„œ í• ë£¨ì‹œë„¤ì´ì…˜(ë°˜ë³µ íŒ¨í„´)ì„ ìë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.
        
        Args:
            time_file: *_time.md íŒŒì¼ ê²½ë¡œ
            
        Returns:
            int: ì œê±°ëœ ì—”íŠ¸ë¦¬ ìˆ˜
        """
        import re
        from collections import Counter
        
        # íŒŒì¼ ì½ê¸°
        with open(time_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # í…Œì´ë¸” ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
        table_start = -1
        for i, line in enumerate(lines):
            if re.match(r'\|\s*\d{2}:\d{2}', line):
                table_start = i
                break
        
        if table_start == -1:
            return 0  # í…Œì´ë¸” ì—†ìŒ
        
        header_lines = lines[:table_start]
        
        # ì—”íŠ¸ë¦¬ íŒŒì‹±
        entries = []
        for line in lines[table_start:]:
            match = re.match(r'\|\s*(\d{2}:\d{2})\s*\|\s*(.+?)\s*\|', line)
            if match:
                entries.append({
                    'time': match.group(1),
                    'content': match.group(2).strip()
                })
        
        if not entries:
            return 0
        
        # ë°˜ë³µ íŒ¨í„´ ê°ì§€ ë° ì œê±°
        cleaned = []
        i = 0
        removed_count = 0
        
        while i < len(entries):
            current_content = entries[i]['content']
            
            # ì—°ì† ë°˜ë³µ ì²´í¬ (3íšŒ ì´ìƒ)
            repeat_count = 1
            j = i + 1
            
            while j < len(entries) and entries[j]['content'] == current_content:
                repeat_count += 1
                j += 1
            
            if repeat_count >= 3:
                # ì²« ë²ˆì§¸ë§Œ ìœ ì§€
                cleaned.append(entries[i])
                removed_count += repeat_count - 1
                i = j
            else:
                # ë‹¨ì–´ ë°˜ë³µ ì œê±°
                words = current_content.split()
                cleaned_words = []
                k = 0
                
                while k < len(words):
                    word = words[k]
                    word_repeat = 1
                    m = k + 1
                    
                    while m < len(words) and words[m] == word:
                        word_repeat += 1
                        m += 1
                    
                    if word_repeat >= 3:
                        cleaned_words.append(word)
                        k = m
                    else:
                        cleaned_words.append(word)
                        k += 1
                
                cleaned_content = ' '.join(cleaned_words)
                
                # ë„ˆë¬´ ì§§ì•„ì§„ ê²½ìš° ì œì™¸
                if len(cleaned_content.strip()) >= 3:
                    cleaned.append({
                        'time': entries[i]['time'],
                        'content': cleaned_content
                    })
                else:
                    removed_count += 1
                
                i += 1
        
        # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ íŒŒì¼ ì¬ì‘ì„±
        if removed_count > 0:
            with open(time_file, 'w', encoding='utf-8') as f:
                # í—¤ë” ì‘ì„±
                f.writelines(header_lines)
                
                # ì—”íŠ¸ë¦¬ ì‘ì„±
                for entry in cleaned:
                    f.write(f"| {entry['time']} | {entry['content']} |\n")
        
        return removed_count
    
    def transcribe_to_file(self, audio_path: str, output_path: str, 
                           include_timestamps: bool = False) -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  íŒŒì¼ë¡œ ì €ì¥.
        
        Args:
            audio_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            include_timestamps: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì—¬ë¶€
            
        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        result = self.transcribe(audio_path, show_timestamps=False)
        
        # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€
        audio_filename = Path(audio_path).name
        
        with open(output_path, "w", encoding="utf-8", errors="replace") as f:
            f.write(f"# Audio Transcription\n")
            f.write(f"# Source: {audio_filename}\n")
            f.write(f"# Language: {result['language']} ({result['language_probability']:.2%})\n")
            f.write(f"# ---\n\n")
            
            if include_timestamps:
                for seg in result['segments']:
                    f.write(f"[{seg['start']:.2f}s - {seg['end']:.2f}s]\n")
                    f.write(f"{seg['text']}\n\n")
            else:
                f.write(result['text'])
        
        print(f"ğŸ“„ ê²°ê³¼ ì €ì¥ë¨: {output_path}")
        
        try:
            info = None  # ì´ˆê¸°í™”
            for segment, info_obj, total_duration, _ in self._transcribe_generator(audio_path, show_progress=True):
                if info is None:
                    info = info_obj
                    # ì–¸ì–´ ì •ë³´ ë“± íŒŒì¼ì— ì—…ë°ì´íŠ¸ (ì„ íƒ ì‚¬í•­, ë³µì¡í•´ì§€ë¯€ë¡œ ìƒëµí•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ì¶”ê°€)

                # 1. ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì¶”ê°€ (Append)
                with open(full_file, "a", encoding="utf-8", errors="replace") as f:
                    text_chunk = segment.text.strip()
                    if text_chunk:
                        # ë¬¸ì¥ ë¶€í˜¸ë¡œ ëë‚˜ë©´ ì¤„ë°”ê¿ˆ, ì•„ë‹ˆë©´ ê³µë°±
                        if text_chunk[-1] in '.!?':
                            f.write(f"{text_chunk}\n")
                        else:
                            f.write(f"{text_chunk} ")

                # 2. ì‹œê°„ êµ¬ê°„ íŒŒì¼ì— ì¶”ê°€ (Append)
                with open(time_file, "a", encoding="utf-8", errors="replace") as f:
                    start_str = format_time(segment.start)
                    # end_str = format_time(segment.end) # í•„ìš”í•œ ê²½ìš° ì‚¬ìš©
                    f.write(f"| {start_str} | {segment.text.strip()} |\n")

        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ëŠ” ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            with open(full_file, "a", encoding="utf-8", errors="replace") as f:
                f.write("\n\n> **âš ï¸ ì¤‘ë‹¨ë¨: ì‚¬ìš©ìì— ì˜í•´ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.**\n")
            with open(time_file, "a", encoding="utf-8", errors="replace") as f:
                f.write("\n> **âš ï¸ ì¤‘ë‹¨ë¨: ì‚¬ìš©ìì— ì˜í•´ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.**\n")
            return time_file, full_file, log_file

        # ì¢…ë£Œ ì²˜ë¦¬
        end_time = time.time()
        elapsed_str = format_time(end_time - start_time)
        
        # ë¡œê·¸ì— ê²°ê³¼ ì—…ë°ì´íŠ¸
        with open(log_file, "a", encoding="utf-8", errors="replace") as f:
            if info:
                f.write(f"| **ì–¸ì–´** | {info.language} ({info.language_probability:.1%}) |\n")
            f.write(f"| **ì†Œìš” ì‹œê°„** | {elapsed_str} |\n\n")

        # íŒŒì¼ ìƒë‹¨ ì •ë³´ ì—…ë°ì´íŠ¸ (ì„ íƒì : íŒŒì¼ì„ ë‹¤ì‹œ ì½ì–´ì„œ í—¤ë” ìˆ˜ì •ì€ ë³µì¡í•˜ë¯€ë¡œ ê¼¬ë¦¬ë§ ì¶”ê°€)
        with open(full_file, "a", encoding="utf-8", errors="replace") as f:
            f.write(f"\n\n---\nâœ… **ë³€í™˜ ì™„ë£Œ** (ì†Œìš” ì‹œê°„: {elapsed_str})")
            
        with open(time_file, "a", encoding="utf-8", errors="replace") as f:
            f.write(f"\n\n---\nâœ… **ë³€í™˜ ì™„ë£Œ** (ì†Œìš” ì‹œê°„: {elapsed_str})")

        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! (ì´ {elapsed_str})")
        print(f"ğŸ“„ ì „ì²´ ë‚´ìš©: {full_file}")
        print(f"ğŸ“„ ì‹œê°„ êµ¬ê°„: {time_file}")
        
        return time_file, full_file, log_file
    
    def transcribe_to_files(self, audio_path: str, output_base: str, 
                            time_interval: int = 30) -> tuple:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ë‘ ê°€ì§€ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì‹¤ì‹œê°„ ê¸°ë¡).
        """
        import time
        from datetime import datetime
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        start_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        date_str = datetime.now().strftime("%Y-%m-%d")
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„± (í•œê¸€ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬)
        output_base_path = Path(output_base)
        time_file = str(output_base_path.with_name(f"{output_base_path.stem}_time.md"))
        full_file = str(output_base_path.with_name(f"{output_base_path.stem}_full.md"))
        
        # ë¡œê·¸ íŒŒì¼ ì¤€ë¹„ (í•œê¸€ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬)
        log_dir = output_base_path.parent / "log"
        log_dir.mkdir(exist_ok=True)
        log_file = str(log_dir / f"{date_str}.md")
        
        # ë¡œê·¸ íŒŒì¼ í—¤ë” (append)
        is_new_log = not os.path.exists(log_file) or os.path.getsize(log_file) == 0
        # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ Path ì‚¬ìš©
        audio_path_obj = Path(audio_path)
        audio_filename = audio_path_obj.name  # UTF-8ë¡œ ì•ˆì „í•˜ê²Œ íŒŒì¼ëª… ì¶”ì¶œ
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
        audio_duration = get_audio_duration(audio_path)
        audio_duration_str = format_time(audio_duration) if audio_duration > 0 else "ì•Œ ìˆ˜ ì—†ìŒ"
        
        # í•œê¸€ ê²½ë¡œ ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ íŒŒì¼ëª…ë§Œ ì‚¬ìš©
        with open(log_file, "a", encoding="utf-8", errors="replace") as f:
            if is_new_log:
                f.write(f"# ğŸ“‹ Transcription Log - {date_str}\n\n")
            f.write(f"---\n\n")
            f.write(f"## ğŸµ {audio_filename}\n\n")
            f.write(f"| í•­ëª© | ê°’ |\n|---|---|\n")
            f.write(f"| **íŒŒì¼** | `{audio_filename}` |\n")
            f.write(f"| **ì˜¤ë””ì˜¤ ê¸¸ì´** | {audio_duration_str} |\n")
            f.write(f"| **ì‹œì‘ ì‹œê°„** | {start_datetime} |\n")
            f.write(f"| **VAD** | {'í™œì„±í™”' if self.use_vad else 'ë¹„í™œì„±í™”'} |\n")
        
        # ì¶œë ¥ íŒŒì¼ ì´ˆê¸°í™”
        with open(full_file, "w", encoding="utf-8", errors="replace") as f:
            f.write(f"# ğŸ“ Audio Transcription - Full Text\n\n")
            f.write(f"> **íŒŒì¼**: `{audio_filename}`  \n")
            f.write(f"> **ìƒíƒœ**: ë³€í™˜ ì¤‘... (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)\n\n---\n\n")
            
        with open(time_file, "w", encoding="utf-8", errors="replace") as f:
            f.write(f"# â±ï¸ Audio Transcription - Time Intervals\n\n")
            f.write(f"> **íŒŒì¼**: `{audio_filename}`  \n")
            f.write(f"> **ìƒíƒœ**: ë³€í™˜ ì¤‘... (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)\n\n---\n\n")
            f.write(f"| ì‹œê°„ | ë‚´ìš© |\n|---|---|\n")

        # ì‹¤ì‹œê°„ ë³€í™˜ ë° ì €ì¥
        info = None
        logged_progress = set()  # ì´ë¯¸ ë¡œê·¸ì— ê¸°ë¡í•œ ì§„í–‰ë¥ 
        segment_count = 0
        
        try:
            for segment, info_obj, total_duration, _ in self._transcribe_generator(audio_path, show_progress=True):
                segment_count += 1
                
                if info is None:
                    info = info_obj
                    # ì–¸ì–´ ì •ë³´ ë¡œê·¸ì— ì—…ë°ì´íŠ¸
                    with open(log_file, "a", encoding="utf-8", errors="replace") as f:
                         f.write(f"| **ì–¸ì–´** | {info.language} ({info.language_probability:.1%}) |\n")

                # ì§„í–‰ë¥  ê³„ì‚°
                if total_duration > 0:
                    progress = segment.end / total_duration * 100
                    progress_int = int(progress)
                    elapsed = time.time() - start_time
                    
                    # ETA ê³„ì‚°
                    if progress > 0:
                        eta = elapsed * (100 - progress) / progress
                        eta_str = format_time(eta)
                    else:
                        eta_str = "?"
                    
                    # ì½˜ì†”ì— ì§„í–‰ë¥  ë°” ì¶œë ¥
                    bar_length = 20
                    filled = int(bar_length * progress / 100)
                    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
                    time_info = f"{format_time(segment.end)}/{format_time(total_duration)}"
                    text_preview = segment.text.strip()[:25]
                    print(f"\r[{bar}] {progress:5.1f}% | {time_info} | ETA: {eta_str} | {text_preview:<25}", end="", flush=True)
                    
                    # ë¡œê·¸ ê¸°ë¡ (10% ë‹¨ìœ„)
                    for milestone in range(10, 100, 10):
                        if progress_int >= milestone and milestone not in logged_progress:
                            logged_progress.add(milestone)
                            with open(log_file, "a", encoding="utf-8", errors="replace") as f:
                                f.write(f"| **ì§„í–‰ë¥ ** | {milestone}% ({format_time(segment.end)}/{format_time(total_duration)}) |\n")
                else:
                    # total_durationì„ ëª¨ë¥¼ ë•Œ
                    print(f"\rì„¸ê·¸ë¨¼íŠ¸ {segment_count} | {format_time(segment.end)} | {segment.text.strip()[:30]:<30}", end="", flush=True)

                # 1. ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì¶”ê°€ (Append)
                with open(full_file, "a", encoding="utf-8", errors="replace") as f:
                    text_chunk = segment.text.strip()
                    if text_chunk:
                        # ë¬¸ì¥ ë¶€í˜¸ë¡œ ëë‚˜ë©´ ì¤„ë°”ê¿ˆ, ì•„ë‹ˆë©´ ê³µë°±
                        if text_chunk[-1] in '.!?':
                            f.write(f"{text_chunk}\n")
                        else:
                            f.write(f"{text_chunk} ")

                # 2. ì‹œê°„ êµ¬ê°„ íŒŒì¼ì— ì¶”ê°€ (Append)
                with open(time_file, "a", encoding="utf-8", errors="replace") as f:
                    start_str = format_time(segment.start)
                    f.write(f"| {start_str} | {segment.text.strip()} |\n")

        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ëŠ” ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            with open(full_file, "a", encoding="utf-8", errors="replace") as f:
                f.write("\n\n> **âš ï¸ ì¤‘ë‹¨ë¨: ì‚¬ìš©ìì— ì˜í•´ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.**\n")
            with open(time_file, "a", encoding="utf-8", errors="replace") as f:
                f.write("\n> **âš ï¸ ì¤‘ë‹¨ë¨: ì‚¬ìš©ìì— ì˜í•´ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.**\n")
            return time_file, full_file, log_file

        # ì¢…ë£Œ ì²˜ë¦¬
        end_time = time.time()
        elapsed_str = format_time(end_time - start_time)
        
        # ë¡œê·¸ì— ê²°ê³¼ ì—…ë°ì´íŠ¸
        with open(log_file, "a", encoding="utf-8", errors="replace") as f:
            f.write(f"| **ì†Œìš” ì‹œê°„** | {elapsed_str} |\n\n")

        # íŒŒì¼ ìƒë‹¨ ì •ë³´ ì—…ë°ì´íŠ¸ (ê¼¬ë¦¬ë§ ì¶”ê°€)
        with open(full_file, "a", encoding="utf-8", errors="replace") as f:
            f.write(f"\n\n---\nâœ… **ë³€í™˜ ì™„ë£Œ** (ì†Œìš” ì‹œê°„: {elapsed_str})")
            
        with open(time_file, "a", encoding="utf-8", errors="replace") as f:
            f.write(f"\n\n---\nâœ… **ë³€í™˜ ì™„ë£Œ** (ì†Œìš” ì‹œê°„: {elapsed_str})")

        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! (ì´ {elapsed_str})")
        print(f"ğŸ“„ ì „ì²´ ë‚´ìš©: {full_file}")
        print(f"ğŸ“„ ì‹œê°„ êµ¬ê°„: {time_file}")
        
        # í• ë£¨ì‹œë„¤ì´ì…˜ ìë™ ì œê±° (ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
        if self.auto_clean_hallucination:
            try:
                print(f"\nğŸ§¹ í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±° ì¤‘...")
                cleaned_count = self._remove_hallucination(time_file)
                if cleaned_count > 0:
                    print(f"   âœ‚ï¸  {cleaned_count}ê°œ ë°˜ë³µ íŒ¨í„´ ì œê±° ì™„ë£Œ")
                else:
                    print(f"   âœ¨ ë°˜ë³µ íŒ¨í„´ ì—†ìŒ (ì •ìƒ)")
            except Exception as e:
                print(f"   âš ï¸  í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±° ì‹¤íŒ¨ (ë¬´ì‹œë¨): {e}")
        
        return time_file, full_file, log_file



def main():
    """CLI ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸."""
    parser = argparse.ArgumentParser(
        description="MP3/WAV íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python mp3_to_text.py audio.mp3                    # ê¸°ë³¸ ë³€í™˜ (audio_time.md, audio_full.md ìƒì„±)
  python mp3_to_text.py audio.mp3 -o result.txt      # ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥
  python mp3_to_text.py audio.mp3 -m large-v3        # ìµœê³  ì •í™•ë„ ëª¨ë¸
  python mp3_to_text.py audio.mp3 -t                 # íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ (--dualê³¼ í•¨ê»˜ ì‚¬ìš©)
  python mp3_to_text.py --dir ./mp3                  # ë””ë ‰í„°ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ì¼ê´„ ë³€í™˜
        """
    )
    
    parser.add_argument("audio_file", nargs="?", help="ë³€í™˜í•  MP3/WAV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("-o", "--output", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ë‹¨ì¼ txt íŒŒì¼ë¡œ ì €ì¥)")
    parser.add_argument("-m", "--model", default="large-v3",
                        choices=["small", "medium", "large", "large-v3"],
                        help="ëª¨ë¸ í¬ê¸° (ê¸°ë³¸: large-v3)")
    parser.add_argument("-l", "--language", default="ko",
                        help="ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: ko í•œêµ­ì–´)")
    parser.add_argument("--device", default="auto",
                        choices=["auto", "cuda", "cpu"],
                        help="ì‹¤í–‰ ì¥ì¹˜ (ê¸°ë³¸: auto)")
    parser.add_argument("-t", "--timestamps", action="store_true",
                        help="íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ")
    parser.add_argument("--dual", action="store_true",
                        help="ë‘ ê°€ì§€ ë²„ì „ ì €ì¥ (_time.md, _full.md)")
    parser.add_argument("--interval", type=int, default=30,
                        help="ì‹œê°„ êµ¬ê°„ (ì´ˆ, ê¸°ë³¸: 30)")
    parser.add_argument("--vad", action="store_true",
                        help="VAD í™œì„±í™” (ìŒì„± êµ¬ê°„ë§Œ ì²˜ë¦¬, ì†ë„ í–¥ìƒ)")
    parser.add_argument("--context", action="store_true",
                        help="ì´ì „ ë¬¸ë§¥ ì°¸ì¡° í™œì„±í™” (ì •í™•ë„ í–¥ìƒ, ì†ë„ ì €í•˜ ê°€ëŠ¥)")
    parser.add_argument("--no-bgm", action="store_true",
                        help="ë°°ê²½ìŒì•… ëª¨ë“œ ë¹„í™œì„±í™” (ê¸°ë³¸ê°’: ë°°ê²½ìŒì•… ëª¨ë“œ í™œì„±í™”)")
    parser.add_argument("--no-clean", action="store_true",
                        help="í• ë£¨ì‹œë„¤ì´ì…˜ ìë™ ì œê±° ë¹„í™œì„±í™” (ê¸°ë³¸ê°’: ìë™ ì œê±° í™œì„±í™”)")
    parser.add_argument("--dir", metavar="DIRECTORY",
                        help="ë””ë ‰í„°ë¦¬ ë‚´ ëª¨ë“  MP3/WAV íŒŒì¼ ì¼ê´„ ë³€í™˜")
    
    args = parser.parse_args()
    
    # ë””ë ‰í„°ë¦¬ ëª¨ë“œ (--dir ì˜µì…˜)
    if args.dir:
        import glob
        
        dir_path = args.dir
        if not os.path.isdir(dir_path):
            print(f"âŒ ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dir_path}")
            sys.exit(1)
        
        # MP3/WAV/M4A íŒŒì¼ ê²€ìƒ‰ (ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ ë””ë ‰í„°ë¦¬ê¹Œì§€ ê²€ìƒ‰)
        dir_path_obj = Path(dir_path)
        audio_files = []
        
        # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        for ext in ['*.mp3', '*.MP3', '*.wav', '*.WAV', '*.m4a', '*.M4A', '*.asf', '*.ASF']:
            audio_files.extend(dir_path_obj.rglob(ext))
        
        # Path ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        audio_files = [str(f) for f in audio_files]
        
        if not audio_files:
            print(f"âš ï¸ ë””ë ‰í„°ë¦¬ì— ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (mp3/wav/m4a/asf): {dir_path}")
            sys.exit(1)
        
        audio_files.sort()
        print(f"\nğŸ“‚ ë””ë ‰í„°ë¦¬: {dir_path}")
        print(f"ğŸµ ë°œê²¬ëœ íŒŒì¼: {len(audio_files)}ê°œ")
        print("=" * 50)
        
        for i, audio_file in enumerate(audio_files):
            # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ Path ì‚¬ìš©
            print(f"  {i+1}. {Path(audio_file).name}")
        print("=" * 50 + "\n")
        
        # ë³€í™˜ê¸° ì´ˆê¸°í™” (1íšŒ)
        use_vad = getattr(args, 'vad', False)
        use_context = getattr(args, 'context', False)
        auto_clean = not getattr(args, 'no_clean', False)
        bgm_mode = not getattr(args, 'no_bgm', False)  # ê¸°ë³¸ê°’: True, --no-bgm ì‹œ False
        
        converter = MP3ToTextConverter(
            model_size=args.model,
            device=args.device,
            language=args.language,
            use_vad=use_vad,
            use_context=use_context,
            bgm_mode=bgm_mode,
            auto_clean_hallucination=auto_clean
        )
        
        # ê° íŒŒì¼ ë³€í™˜
        success_count = 0
        fail_count = 0
        
        for i, audio_file in enumerate(audio_files):
            # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ Path ì‚¬ìš©
            print(f"\n[{i+1}/{len(audio_files)}] ì²˜ë¦¬ ì¤‘: {Path(audio_file).name}")
            print("-" * 50)
            
            try:
                # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„± (í™•ì¥ì ì œê±°)
                base_name = os.path.splitext(audio_file)[0]
                
                converter.transcribe_to_files(
                    audio_file,
                    base_name,
                    time_interval=args.interval
                )
                success_count += 1
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
                fail_count += 1
        
        # ìµœì¢… ìš”ì•½
        print(f"\n" + "=" * 50)
        print(f"ğŸ‰ ì¼ê´„ ë³€í™˜ ì™„ë£Œ!")
        print(f"   âœ… ì„±ê³µ: {success_count}ê°œ")
        if fail_count > 0:
            print(f"   âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
        print("=" * 50)
    
    # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ
    elif args.audio_file is None:
        print("=" * 50)
        print("ğŸ¤ MP3 â†’ í…ìŠ¤íŠ¸ ë³€í™˜ê¸° (ë¬´ë£Œ ë¡œì»¬ ì‹¤í–‰)")
        print("=" * 50)
        print("\nëª¨ë¸ í¬ê¸° ì˜µì…˜:")
        for name, info in MP3ToTextConverter.MODEL_INFO.items():
            print(f"  â€¢ {name}: {info['size']} / {info['speed']} / ì •í™•ë„: {info['accuracy']}")
        
        print("\níŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: q):")
        
        converter = None
        while True:
            audio_path = input("\nğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼: ").strip()
            
            if audio_path.lower() == 'q':
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not audio_path:
                continue
                
            # ì²¨ ë²ˆì§¸ íŒŒì¼ ì²˜ë¦¬ ì‹œ ëª¨ë¸ ë¡œë“œ
            if converter is None:
                model_choice = input("ëª¨ë¸ ì„ íƒ (small/medium/large/large-v3) [large-v3]: ").strip()
                if model_choice not in MP3ToTextConverter.MODEL_INFO:
                    model_choice = "large-v3"
                
                converter = MP3ToTextConverter(model_size=model_choice)
            
            try:
                result = converter.transcribe(audio_path, show_timestamps=args.timestamps)
                print("\nğŸ“ ë³€í™˜ ê²°ê³¼:")
                print("-" * 40)
                print(result['text'])
                print("-" * 40)
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
    else:
        # CLI ëª¨ë“œ (ë‹¨ì¼ íŒŒì¼)
        use_vad = getattr(args, 'vad', False)
        use_context = getattr(args, 'context', False)
        auto_clean = not getattr(args, 'no_clean', False)
        bgm_mode = not getattr(args, 'no_bgm', False)  # ê¸°ë³¸ê°’: True, --no-bgm ì‹œ False
        
        converter = MP3ToTextConverter(
            model_size=args.model,
            device=args.device,
            language=args.language,
            use_vad=use_vad,
            use_context=use_context,
            bgm_mode=bgm_mode,
            auto_clean_hallucination=auto_clean
        )
        
        if args.dual:
            # ë‘ ê°€ì§€ ë²„ì „ ì €ì¥ (_time.md, _full.md)
            # -o ì˜µì…˜ì´ ìˆìœ¼ë©´ ê·¸ ê°’ ì‚¬ìš©, ì—†ìœ¼ë©´ ì…ë ¥ íŒŒì¼ëª…ì—ì„œ ìë™ ìƒì„±
            if args.output:
                output_base = args.output
                if output_base.endswith('.txt') or output_base.endswith('.md'):
                    output_base = output_base[:-4] if output_base.endswith('.txt') else output_base[:-3]
            else:
                # ì…ë ¥ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ì¶œë ¥ ê²½ë¡œ ìƒì„±
                output_base = os.path.splitext(args.audio_file)[0]
            
            converter.transcribe_to_files(
                args.audio_file,
                output_base,
                time_interval=args.interval
            )
        elif args.output:
            # ë‹¨ì¼ íŒŒì¼ ì €ì¥
            converter.transcribe_to_file(
                args.audio_file, 
                args.output,
                include_timestamps=args.timestamps
            )
        else:
            # ê¸°ë³¸: ì…ë ¥ íŒŒì¼ëª… ê¸°ì¤€ìœ¼ë¡œ ë‘ ê°€ì§€ ë²„ì „ ì €ì¥ (_time.md, _full.md)
            # í•œê¸€ ê²½ë¡œ ì•ˆì „ ì²˜ë¦¬: ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì •í™•í•œ íŒŒì¼ ì°¾ê¸°
            audio_file_input = args.audio_file
            
            # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
            audio_file_path = None
            
            # 1ë‹¨ê³„: ì§ì ‘ ê²½ë¡œ í™•ì¸ (Path ê°ì²´ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
            try:
                audio_file_path_obj = Path(audio_file_input).resolve()
                if audio_file_path_obj.exists() and audio_file_path_obj.is_file():
                    audio_file_path = audio_file_path_obj
            except (OSError, ValueError):
                pass
            
            # 2ë‹¨ê³„: íŒŒì¼ì´ ì—†ìœ¼ë©´ ë””ë ‰í„°ë¦¬ì—ì„œ ì°¾ê¸°
            if audio_file_path is None or not audio_file_path.exists():
                # ë””ë ‰í„°ë¦¬ ê²½ë¡œ íŒŒì‹±
                try:
                    input_path_obj = Path(audio_file_input)
                    dir_path = input_path_obj.parent if input_path_obj.parent != Path('.') else Path('.')
                    input_filename = input_path_obj.name
                    ext = input_path_obj.suffix or '.mp3'
                except:
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                    dir_path = Path(os.path.dirname(audio_file_input) or ".")
                    input_filename = os.path.basename(audio_file_input)
                    ext = os.path.splitext(input_filename)[1] or '.mp3'
                
                # ë””ë ‰í„°ë¦¬ì—ì„œ ì‹¤ì œ íŒŒì¼ ì°¾ê¸°
                if dir_path.exists() and dir_path.is_dir():
                    candidates = []
                    
                    # ë””ë ‰í„°ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ê²€ì‚¬
                    for f in os.listdir(str(dir_path)):
                        file_path = dir_path / f
                        
                        # íŒŒì¼ì´ê³  í™•ì¥ìê°€ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
                        if file_path.is_file() and f.lower().endswith(ext.lower()):
                            # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
                            score = 0
                            
                            # ì…ë ¥ íŒŒì¼ëª…ì˜ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œê¸€ ê¹¨ì§ ëŒ€ì‘)
                            # ì›ë³¸ ì…ë ¥ì—ì„œ í•œê¸€ ë¬¸ì ì¶”ì¶œ ì‹œë„
                            keywords = []
                            try:
                                # ì…ë ¥ íŒŒì¼ëª…ì´ë‚˜ ì›ë³¸ ì¸ìì—ì„œ í•œê¸€ ë¬¸ì í™•ì¸
                                full_input = f"{input_filename} {audio_file_input}"
                                # í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„: AC00-D7AF
                                korean_chars = [c for c in full_input if '\uAC00' <= c <= '\uD7AF']
                                if korean_chars:
                                    # ì—°ì†ëœ í•œê¸€ ë¬¸ì ì¡°í•©ì„ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
                                    korean_text = ''.join(korean_chars)
                                    # ìì£¼ ì‚¬ìš©ë˜ëŠ” í‚¤ì›Œë“œ í™•ì¸
                                    if "ì •ì€ì„" in full_input or "ì •ì€ì„" in korean_text:
                                        keywords.append("ì •ì€ì„")
                                    if "ë§ˆì§€ë§‰" in full_input or "ë§ˆì§€ë§‰" in korean_text:
                                        keywords.append("ë§ˆì§€ë§‰")
                                    if "ë°©ì†¡" in full_input or "ë°©ì†¡" in korean_text:
                                        keywords.append("ë°©ì†¡")
                                    # ì¼ë°˜ì ì¸ í•œê¸€ íŒ¨í„´ ë§¤ì¹­ (ìµœì†Œ 2ì ì´ìƒ)
                                    if len(korean_text) >= 2:
                                        # íŒŒì¼ëª…ì—ì„œ í•´ë‹¹ í•œê¸€ ë¬¸ìë“¤ì´ ëª¨ë‘ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                                        if all(k in f for k in korean_chars[:3]):  # ì²˜ìŒ 3ê°œ ë¬¸ìë§Œ í™•ì¸
                                            score += 20
                            except:
                                pass
                            
                            # íŒŒì¼ëª…ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´ ì ìˆ˜ ì¦ê°€
                            for keyword in keywords:
                                if keyword in f:
                                    score += 30  # í‚¤ì›Œë“œ ë§¤ì¹­ì— ë” ë†’ì€ ì ìˆ˜
                            
                            # í™•ì¥ì ì¼ì¹˜ ì ìˆ˜
                            if f.lower().endswith(ext.lower()):
                                score += 1
                            
                            candidates.append((score, file_path))
                    
                    # ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                    if candidates:
                        candidates.sort(key=lambda x: x[0], reverse=True)
                        audio_file_path = candidates[0][1]
                        if audio_file_path != candidates[0][1]:
                            print(f"ğŸ“ íŒŒì¼ ì°¾ìŒ: {audio_file_path.name}")
            
            # 3ë‹¨ê³„: ìµœì¢… í™•ì¸
            if audio_file_path is None or not audio_file_path.exists():
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.audio_file}")
                print(f"ğŸ’¡ íŒ: --dir ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ í•œê¸€ íŒŒì¼ëª… ë¬¸ì œë¥¼ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                print(f"   ì˜ˆ: python src/mp3_to_text.py --dir ./mp3")
                sys.exit(1)
            
            output_base = str(audio_file_path.parent / audio_file_path.stem)
            converter.transcribe_to_files(
                str(audio_file_path),
                output_base,
                time_interval=args.interval
            )


if __name__ == "__main__":
    main()
