#!/usr/bin/env python3
"""
STT ê²°ê³¼ì—ì„œ í• ë£¨ì‹œë„¤ì´ì…˜(ë°˜ë³µ íŒ¨í„´) ìë™ ê°ì§€ ë° ì œê±° ìŠ¤í¬ë¦½íŠ¸
"""

import re
from pathlib import Path
from collections import Counter
import argparse


def detect_repeated_content(lines, threshold=3):
    """
    ë°˜ë³µë˜ëŠ” ë‚´ìš©ì„ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        lines: ë¶„ì„í•  ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        threshold: ë°˜ë³µìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ íšŸìˆ˜
    
    Returns:
        ë°˜ë³µ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸ [(start_idx, end_idx, repeated_text), ...]
    """
    repeated_sections = []
    i = 0
    
    while i < len(lines):
        # í˜„ì¬ ë¼ì¸ë¶€í„° ì—°ì†ëœ ë™ì¼/ìœ ì‚¬ ë‚´ìš© ì°¾ê¸°
        current_content = lines[i].strip()
        if not current_content or len(current_content) < 5:
            i += 1
            continue
        
        # ê°™ì€ ë‚´ìš©ì´ ì—°ì†ìœ¼ë¡œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸
        repeat_count = 1
        j = i + 1
        
        while j < len(lines):
            next_content = lines[j].strip()
            # ì™„ì „íˆ ê°™ê±°ë‚˜ ë§¤ìš° ìœ ì‚¬í•œ ê²½ìš° (80% ì´ìƒ ì¼ì¹˜)
            if next_content == current_content or similarity(current_content, next_content) > 0.8:
                repeat_count += 1
                j += 1
            else:
                break
        
        if repeat_count >= threshold:
            repeated_sections.append((i, j - 1, current_content))
            i = j
        else:
            i += 1
    
    return repeated_sections


def similarity(s1, s2):
    """ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚° (0.0 ~ 1.0)"""
    if not s1 or not s2:
        return 0.0
    
    # ê°„ë‹¨í•œ Jaccard ìœ ì‚¬ë„
    set1 = set(s1)
    set2 = set(s2)
    intersection = len(set1 & set2)
    union = len(set1 | set2)
    
    return intersection / union if union > 0 else 0.0


def detect_short_repeats(content, threshold=5):
    """
    ì§§ì€ êµ¬ë¬¸ì´ ë°˜ë³µë˜ëŠ” íŒ¨í„´ ê°ì§€ (ì˜ˆ: "ì˜¤í¼ë¥¼ ì¢‹ì•„í•´?" ë°˜ë³µ)
    
    Args:
        content: ì „ì²´ ë‚´ìš©
        threshold: ë°˜ë³µìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ íšŸìˆ˜
    
    Returns:
        ë°˜ë³µ íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
    """
    # ì§§ì€ êµ¬ë¬¸ íŒ¨í„´ ì°¾ê¸° (2-15ì ì •ë„)
    patterns = re.findall(r'(.{2,15}?)\1{' + str(threshold-1) + r',}', content)
    return list(set(patterns))  # ì¤‘ë³µ ì œê±°


def parse_time_md_file(file_path):
    """
    time.md íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    Returns:
        (header_lines, entries): í—¤ë”ì™€ ì—”íŠ¸ë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # í—¤ë” ë¶€ë¶„ ì°¾ê¸° (í…Œì´ë¸” ì‹œì‘ ì „ê¹Œì§€)
    table_start = -1
    for i, line in enumerate(lines):
        if line.strip().startswith('| ì‹œê°„ | ë‚´ìš© |') or \
           re.match(r'\|\s*\d{2}:\d{2}', line):
            # í…Œì´ë¸” í—¤ë” ë‹¤ìŒì— êµ¬ë¶„ì„ ì´ ìˆëŠ”ì§€ í™•ì¸
            if i > 0 and '|---|---|' in lines[i-1]:
                table_start = i
                break
            elif i < len(lines) - 1 and '|---|---|' in lines[i+1]:
                table_start = i + 2
                break
    
    if table_start == -1:
        return lines, []
    
    header_lines = lines[:table_start]
    
    # í…Œì´ë¸” ì—”íŠ¸ë¦¬ íŒŒì‹±
    entries = []
    for line in lines[table_start:]:
        match = re.match(r'\|\s*(\d{2}:\d{2})\s*\|\s*(.+?)\s*\|', line)
        if match:
            time_str = match.group(1)
            content = match.group(2).strip()
            entries.append({
                'time': time_str,
                'content': content,
                'original_line': line
            })
    
    return header_lines, entries


def clean_repeated_words(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì—°ì†ìœ¼ë¡œ ë°˜ë³µë˜ëŠ” ë‹¨ì–´ë‚˜ êµ¬ë¬¸ì„ ì œê±°í•©ë‹ˆë‹¤.
    ì˜ˆ: "ê·¸ë…€ëŠ” ê·¸ë…€ëŠ” ê·¸ë…€ëŠ”" -> "ê·¸ë…€ëŠ”"
    """
    # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ ë°˜ë³µ ì œê±°
    words = text.split()
    cleaned_words = []
    i = 0
    
    while i < len(words):
        word = words[i]
        # ê°™ì€ ë‹¨ì–´ê°€ ì—°ì†ìœ¼ë¡œ 3ë²ˆ ì´ìƒ ë‚˜ì˜¤ë©´ 1ë²ˆë§Œ ë‚¨ê¹€
        repeat_count = 1
        j = i + 1
        
        while j < len(words) and words[j] == word:
            repeat_count += 1
            j += 1
        
        if repeat_count >= 3:
            cleaned_words.append(word)
            i = j
        else:
            cleaned_words.append(word)
            i += 1
    
    result = ' '.join(cleaned_words)
    
    # ë¬¸ì ë‹¨ìœ„ ë°˜ë³µ íŒ¨í„´ ì œê±° (ì˜ˆ: "ë¶ˆì— ë¶ˆì— ë¶ˆì„")
    # 2-10ì ì •ë„ì˜ ì§§ì€ êµ¬ë¬¸ì´ 2ë²ˆ ì´ìƒ ë°˜ë³µë˜ëŠ” ê²½ìš°
    result = re.sub(r'(.{2,10}?)\1{2,}', r'\1', result)
    
    return result.strip()


def is_likely_hallucination(content):
    """
    í• ë£¨ì‹œë„¤ì´ì…˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‚´ìš©ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤.
    """
    # ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ê²½ìš°
    if len(content) < 2:
        return True
    
    # ê°™ì€ ê¸€ìê°€ 80% ì´ìƒì¸ ê²½ìš°
    if len(content) > 10:
        char_counts = Counter(content)
        most_common_char, count = char_counts.most_common(1)[0]
        if count / len(content) > 0.8:
            return True
    
    # ì˜ë¯¸ ì—†ëŠ” ë°˜ë³µ íŒ¨í„´
    meaningless_patterns = [
        r'^(.{1,3})\1{5,}',  # 1-3ê¸€ìê°€ 5ë²ˆ ì´ìƒ ë°˜ë³µ
        r'^[ã„±-ã…ã…-ã…£]+$',  # ììŒ/ëª¨ìŒë§Œ
        r'^([a-zA-Z])\1{10,}',  # ê°™ì€ ì•ŒíŒŒë²³ 10ë²ˆ ì´ìƒ
    ]
    
    for pattern in meaningless_patterns:
        if re.match(pattern, content):
            return True
    
    return False


def clean_entries(entries, verbose=False):
    """
    ì—”íŠ¸ë¦¬ì—ì„œ ë°˜ë³µ íŒ¨í„´ì„ ì œê±°í•©ë‹ˆë‹¤.
    """
    if not entries:
        return entries
    
    cleaned = []
    contents = [e['content'] for e in entries]
    
    # 1. ì—°ì†ëœ ë™ì¼ ë‚´ìš© ê°ì§€
    repeated_sections = detect_repeated_content(contents, threshold=3)
    
    if verbose and repeated_sections:
        print("\nğŸ” ê°ì§€ëœ ë°˜ë³µ êµ¬ê°„:")
        for start, end, text in repeated_sections:
            print(f"  - ë¼ì¸ {start+1}~{end+1}: \"{text[:50]}...\" ({end-start+1}íšŒ ë°˜ë³µ)")
    
    # 2. ì§§ì€ êµ¬ë¬¸ ë°˜ë³µ íŒ¨í„´ ê°ì§€
    full_content = ' '.join(contents)
    short_patterns = detect_short_repeats(full_content, threshold=5)
    
    if verbose and short_patterns:
        print("\nğŸ” ê°ì§€ëœ ì§§ì€ ë°˜ë³µ íŒ¨í„´:")
        for pattern in short_patterns:
            print(f"  - \"{pattern}\"")
    
    # 3. ì œê±°í•  ë¼ì¸ ì¸ë±ìŠ¤ ìˆ˜ì§‘
    skip_indices = set()
    for start, end, _ in repeated_sections:
        # ì²« ë²ˆì§¸ëŠ” ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì œê±°
        for idx in range(start + 1, end + 1):
            skip_indices.add(idx)
    
    # 4. í´ë¦°í•œ ì—”íŠ¸ë¦¬ ìƒì„±
    for i, entry in enumerate(entries):
        if i in skip_indices:
            continue
        
        content = entry['content']
        original_content = content
        
        # í• ë£¨ì‹œë„¤ì´ì…˜ ê°€ëŠ¥ì„± ì²´í¬
        if is_likely_hallucination(content):
            if verbose:
                print(f"\nğŸ—‘ï¸  ë¼ì¸ {i+1} ì œê±° (í• ë£¨ì‹œë„¤ì´ì…˜ ì˜ì‹¬):")
                print(f"   ë‚´ìš©: {content[:80]}...")
            continue
        
        # ì§§ì€ íŒ¨í„´ ë°˜ë³µ ì œê±°
        for pattern in short_patterns:
            if pattern in content:
                parts = content.split(pattern)
                if len(parts) > 2:  # 2ë²ˆ ì´ìƒ ë°˜ë³µ
                    content = pattern + ''.join(parts[1:]).replace(pattern, '').strip()
        
        # ì—°ì† ë°˜ë³µ ë‹¨ì–´ ì •ë¦¬
        content = clean_repeated_words(content)
        
        # ë„ˆë¬´ ì§§ì•„ì§„ ê²½ìš° ì œê±°
        if len(content.strip()) < 3:
            if verbose:
                print(f"\nğŸ—‘ï¸  ë¼ì¸ {i+1} ì œê±° (ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ):")
                print(f"   ì›ë³¸: {original_content[:80]}...")
            continue
        
        if content != original_content and verbose:
            print(f"\nâœ‚ï¸  ë¼ì¸ {i+1} ì •ë¦¬:")
            print(f"   ì´ì „: {original_content[:80]}...")
            print(f"   ì´í›„: {content[:80]}...")
        
        cleaned.append({
            'time': entry['time'],
            'content': content,
            'original_line': entry['original_line']
        })
    
    return cleaned


def write_cleaned_file(file_path, header_lines, cleaned_entries, backup=True):
    """
    ì •ë¦¬ëœ ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # ë°±ì—… ìƒì„±
    if backup:
        backup_path = str(file_path).replace('.md', '.backup.md')
        with open(backup_path, 'w', encoding='utf-8') as f:
            with open(file_path, 'r', encoding='utf-8') as original:
                f.write(original.read())
        print(f"\nğŸ’¾ ë°±ì—… ì €ì¥: {backup_path}")
    
    # ìƒˆ íŒŒì¼ ì‘ì„±
    with open(file_path, 'w', encoding='utf-8') as f:
        # í—¤ë” ì‘ì„±
        f.writelines(header_lines)
        
        # ì—”íŠ¸ë¦¬ ì‘ì„±
        for entry in cleaned_entries:
            f.write(f"| {entry['time']} | {entry['content']} |\n")
    
    print(f"âœ… ì •ë¦¬ ì™„ë£Œ: {file_path}")


def main():
    parser = argparse.ArgumentParser(
        description='STT ê²°ê³¼ íŒŒì¼ì—ì„œ í• ë£¨ì‹œë„¤ì´ì…˜(ë°˜ë³µ íŒ¨í„´) ì œê±°'
    )
    parser.add_argument('file', type=str, help='ì²˜ë¦¬í•  *_time.md íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--no-backup', action='store_true', help='ë°±ì—… íŒŒì¼ ìƒì„± ì•ˆ í•¨')
    parser.add_argument('-v', '--verbose', action='store_true', help='ìƒì„¸ ì •ë³´ ì¶œë ¥')
    parser.add_argument('--threshold', type=int, default=3, 
                        help='ë°˜ë³µìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3)')
    
    args = parser.parse_args()
    
    file_path = Path(args.file)
    
    if not file_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return 1
    
    print(f"ğŸ“„ ë¶„ì„ ì¤‘: {file_path.name}")
    
    # íŒŒì¼ íŒŒì‹±
    header_lines, entries = parse_time_md_file(file_path)
    
    if not entries:
        print("âŒ í…Œì´ë¸” ì—”íŠ¸ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return 1
    
    print(f"ğŸ“Š ì´ {len(entries)}ê°œ ì—”íŠ¸ë¦¬ ë°œê²¬")
    
    # í´ë¦¬ë‹
    cleaned_entries = clean_entries(entries, verbose=args.verbose)
    
    removed_count = len(entries) - len(cleaned_entries)
    print(f"\nğŸ“ˆ í†µê³„:")
    print(f"   ì›ë³¸: {len(entries)}ê°œ ì—”íŠ¸ë¦¬")
    print(f"   ì •ë¦¬ í›„: {len(cleaned_entries)}ê°œ ì—”íŠ¸ë¦¬")
    print(f"   ì œê±°ë¨: {removed_count}ê°œ ({removed_count/len(entries)*100:.1f}%)")
    
    # ì €ì¥
    if removed_count > 0:
        write_cleaned_file(file_path, header_lines, cleaned_entries, backup=not args.no_backup)
    else:
        print("\nâœ¨ ì œê±°í•  ë°˜ë³µ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    return 0


if __name__ == '__main__':
    exit(main())
